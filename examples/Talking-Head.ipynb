{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700347f5",
   "metadata": {},
   "source": [
    "Please follow the procedure in ```./assets/README-talking-head.md``` to create talking head video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8d482f5-58ae-46d4-83e4-dffbd8f618d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory:  /home/peizhi/Documents/gaussian-dejavu\n",
      "creating the FLAME Decoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peizhi/Documents/gaussian-dejavu/utils/flame_lib/FLAME.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('dynamic_lmk_faces_idx', torch.tensor(lmk_embeddings['dynamic_lmk_faces_idx'], dtype=torch.long))\n",
      "/home/peizhi/Documents/gaussian-dejavu/utils/flame_lib/FLAME.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer('dynamic_lmk_bary_coords', torch.tensor(lmk_embeddings['dynamic_lmk_bary_coords'], dtype=self.dtype))\n",
      "/home/peizhi/miniconda3/envs/dejavu/lib/python3.10/site-packages/pytorch3d/io/obj_io.py:550: UserWarning: Mtl file does not exist: ./models/head_template2.mtl\n",
      "  warnings.warn(f\"Mtl file does not exist: {f}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Framework v1.0 initialized.\n",
      "Number of Gaussians:  74083\n",
      "model loaded from:  ./models/dejavu_network.pt\n",
      "Gaussian DejaVu Framework Created.\n",
      "Head avatar parameters loaded\n"
     ]
    }
   ],
   "source": [
    "## Enviroment Setup\n",
    "import os, sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # Set the visible CUDA, here we use the second GPU\n",
    "WORKING_DIR = '/home/peizhi/Documents/gaussian-dejavu/'\n",
    "os.chdir(WORKING_DIR) # change the working directory to the project's absolute path\n",
    "print(\"Current Working Directory: \", os.getcwd())\n",
    "sys.path.append(WORKING_DIR)\n",
    "sys.path.append('./models')\n",
    "sys.path.append('./networks')\n",
    "sys.path.append('./utils')\n",
    "sys.path.append('./utils/flame_lib/')\n",
    "sys.path.append('./utils/diff-gaussian-rasterization')\n",
    "sys.path.append('./utils/gaussian_renderer')\n",
    "sys.path.append('./utils/scene')\n",
    "sys.path.append('./utils/arguments')\n",
    "sys.path.append('./utils/simple-knn')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from dejavu import GaussianDejavu\n",
    "\n",
    "def min_max_normalize(image):\n",
    "    norm_image = (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "    return norm_image\n",
    "\n",
    "def blur_head_boundary(rendered_img, blur_kernel_size=25, erode_kernel_size=20, sigma=5):\n",
    "    # rendered_img: RGB numpy array, float32\n",
    "    # Ensure image is in 0-255 range if given in 0-1\n",
    "    rendered_img = (np.clip(rendered_img, 0, 1.0) * 255).astype(np.uint8)\n",
    "    gray = cv2.cvtColor(rendered_img, cv2.COLOR_BGR2GRAY)\n",
    "    _, binary_mask = cv2.threshold(gray, 254, 255, cv2.THRESH_BINARY_INV)\n",
    "    eroded_mask = 255 - cv2.erode(binary_mask, np.ones((erode_kernel_size, erode_kernel_size), np.uint8), iterations=1)\n",
    "    blurred_boundary = cv2.GaussianBlur(rendered_img, (blur_kernel_size, blur_kernel_size), sigmaX=sigma, sigmaY=sigma)\n",
    "    alpha = cv2.GaussianBlur(eroded_mask.astype(float) / 255.0, (blur_kernel_size, blur_kernel_size), sigmaX=sigma*2)\n",
    "    blurred_img = (alpha[..., None] * blurred_boundary + (1 - alpha[..., None]) * rendered_img)\n",
    "    return blurred_img / 255.\n",
    "\n",
    "\n",
    "dejavu = GaussianDejavu(network_weights='./models/dejavu_network.pt')\n",
    "device = dejavu.device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d32131ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head avatar parameters loaded\n"
     ]
    }
   ],
   "source": [
    "## load head avatar\n",
    "# dejavu.load_head_avatar(save_path='./saved_avatars', avatar_name='peizhi-uv320-1.1')\n",
    "# dejavu.load_head_avatar(save_path='./saved_avatars', avatar_name='peizhi-cartoon-uv320-v1.1')\n",
    "# dejavu.load_head_avatar(save_path='./saved_avatars', avatar_name='imavatar-subject1-uv320-1.1')\n",
    "dejavu.load_head_avatar(save_path='./saved_avatars', avatar_name='imavatar-subject2-uv320-1.1')\n",
    "\n",
    "\n",
    "# the sequence of driving parameters is from Unitalker\n",
    "loaded_sequences = np.load('./assets/can_you_feel_the_love_tonight_clip.npy', allow_pickle=True) \n",
    "\n",
    "video_export_path = '/home/peizhi/Desktop/exported_video.mp4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ed63b4",
   "metadata": {},
   "source": [
    "### Render Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67f6e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/866 [00:00<?, ?it/s]/home/peizhi/Documents/gaussian-dejavu/utils/scene/cameras.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  world_view_transform = torch.tensor(cam.world_view_transform).float().to(device)\n",
      "/home/peizhi/Documents/gaussian-dejavu/utils/scene/cameras.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  full_proj_transform = torch.tensor(cam.full_proj_transform).float().to(device)\n",
      "100%|██████████| 866/866 [00:37<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Exported!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Render frames\n",
    "frames = []\n",
    "for frame_id in tqdm(range(len(loaded_sequences['exp']))):\n",
    "    \n",
    "    # prepare driving parameters\n",
    "    exp = loaded_sequences['exp'][frame_id:frame_id+1, :50] * 1.2\n",
    "    exp = np.clip(exp, -1.5, 1.5)\n",
    "    jaw = loaded_sequences['jaw'][frame_id:frame_id+1, :]\n",
    "    pose = np.zeros([1,6], dtype=np.float32)\n",
    "    pose[:,3:] = jaw * 3.0\n",
    "    pose[:,3] = np.clip(pose[:,3] + 0.2, 0.015, 0.3) # correct the jaw up/down to valid range\n",
    "    \n",
    "    # render via dejavu\n",
    "    rendered = dejavu.drive_head_avatar(exp=exp, pose=pose, eye_pose=None, cam_pose=None, return_all=False)\n",
    "    rendered = rendered[0].permute(1,2,0).cpu().numpy()\n",
    "    rendered = blur_head_boundary(rendered_img=rendered)\n",
    "    frames.append(rendered)\n",
    "\n",
    "\n",
    "## Save video\n",
    "height, width, _ = frames[0].shape\n",
    "fps = loaded_sequences['fps']  # should match that used in Unitalker\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID' for .avi\n",
    "out = cv2.VideoWriter(video_export_path, fourcc, fps, (width, height))\n",
    "for frame in frames:\n",
    "    # Ensure uint8\n",
    "    if frame.dtype != np.uint8:\n",
    "        frame = (np.clip(frame, 0,1.0) * 255).clip(0,255).astype('uint8')\n",
    "    # Convert RGB to BGR for OpenCV\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    out.write(frame_bgr)\n",
    "out.release()\n",
    "print('Video Exported!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265535ab",
   "metadata": {},
   "source": [
    "### Add Original Audio to the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5949e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "  built with gcc 13 (Ubuntu 13.2.0-23ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=3ubuntu5 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --disable-omx --enable-gnutls --enable-libaom --enable-libass --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgme --enable-libgsm --enable-libharfbuzz --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-openal --enable-opencl --enable-opengl --disable-sndio --enable-libvpl --disable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-ladspa --enable-libbluray --enable-libjack --enable-libpulse --enable-librabbitmq --enable-librist --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libx264 --enable-libzmq --enable-libzvbi --enable-lv2 --enable-sdl2 --enable-libplacebo --enable-librav1e --enable-pocketsphinx --enable-librsvg --enable-libjxl --enable-shared\n",
      "  libavutil      58. 29.100 / 58. 29.100\n",
      "  libavcodec     60. 31.102 / 60. 31.102\n",
      "  libavformat    60. 16.100 / 60. 16.100\n",
      "  libavdevice    60.  3.100 / 60.  3.100\n",
      "  libavfilter     9. 12.100 /  9. 12.100\n",
      "  libswscale      7.  5.100 /  7.  5.100\n",
      "  libswresample   4. 12.100 /  4. 12.100\n",
      "  libpostproc    57.  3.100 / 57.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/home/peizhi/Desktop/exported_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf59.27.100\n",
      "  Duration: 00:00:28.87, start: 0.000000, bitrate: 257 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 512x512 [SAR 1:1 DAR 1:1], 256 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "[aist#1:0/pcm_s16le @ 0x64e88c45c700] Guessed Channel Layout: mono\n",
      "Input #1, wav, from '/home/peizhi/Desktop/can_you_feel_the_love_tonight_clip.wav':\n",
      "  Duration: 00:00:28.85, bitrate: 705 kb/s\n",
      "  Stream #1:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "  Stream #1:0 -> #0:1 (pcm_s16le (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, mp4, to '/home/peizhi/Desktop/video_with_audio.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf60.16.100\n",
      "  Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 512x512 [SAR 1:1 DAR 1:1], q=2-31, 256 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1: Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 69 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc60.31.102 aac\n",
      "size=       0kB time=-00:00:00.02 bitrate=  -0.0kbits/s speed=N/A    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output saved to: /home/peizhi/Desktop/video_with_audio.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[out#0/mp4 @ 0x64e88c4360c0] video:902kB audio:245kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 2.226338%\n",
      "size=    1172kB time=00:00:28.83 bitrate= 333.0kbits/s speed= 116x    \n",
      "[aac @ 0x64e88c461bc0] Qavg: 170.770\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# need to edit the paths before running!!\n",
    "video_path = '/home/peizhi/Desktop/exported_video.mp4'                     # rendered video file\n",
    "audio_path = '/home/peizhi/Desktop/can_you_feel_the_love_tonight_clip.wav' # original audio file\n",
    "output_path = '/home/peizhi/Desktop/video_with_audio.mp4'                  # final video save path\n",
    "\n",
    "# Mux audio with video\n",
    "subprocess.run([\n",
    "    'ffmpeg', '-y', '-i', video_path, '-i', audio_path,\n",
    "    '-c:v', 'copy', '-c:a', 'aac', '-shortest',\n",
    "    output_path\n",
    "])\n",
    "\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8989723b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eacff74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dejavu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
